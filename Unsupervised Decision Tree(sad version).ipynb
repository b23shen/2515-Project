{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e06d7804",
   "metadata": {},
   "source": [
    "## Unsupervised Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d4652ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the required libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5c7f4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['Shoes']\n",
    "features = ['RGB']\n",
    "\n",
    "\n",
    "output_dir = \"./unsupervised_results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fcf068e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(feature):\n",
    "    X_train = np.load( \"./Shoes\" + \"/\" + feature + \"/X_train_\" + feature + \".npy\")\n",
    "    X_test = np.load( \"./Shoes\"+ \"/\" + feature + \"/X_test_\" + feature + \".npy\")\n",
    "    y_train = np.load( \"./Shoes\" + \"/\" + feature + \"/y_train_\" + feature + \".npy\")\n",
    "    y_test = np.load( \"./Shoes\" + \"/\" + feature + \"/y_test_\" + feature + \".npy\")\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a19f5b2",
   "metadata": {},
   "source": [
    "## DecisionTree: max_leaf_nodes = num of class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3e6658d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare dataset\n",
    "# # CHANGE THIS\n",
    "# X_train = np.load(\"./supervised/final_results/Shoes/RGB/X_train_RGB.npy\")\n",
    "# X_test = np.load(\"./supervised/final_results/Shoes/RGB/X_test_RGB.npy\")\n",
    "# y_test = np.load(\"./supervised/final_results/Shoes/RGB/y_test_RGB.npy\")\n",
    "# y_train = np.load(\"./supervised/final_results/Shoes/RGB/y_train_RGB.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7e45c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, X_test, y_test, y_train, number_of_class):\n",
    "    '''\n",
    "    We treat this as a regression problem, basically just treat the dataset as our label. \n",
    "    Spliting the decision tree based on the variance reduction rule.\n",
    "    Returns the test dataset with assigned cluster index\n",
    "    '''\n",
    "    # Regression Decision Tree\n",
    "    reg = DecisionTreeRegressor(criterion=\"squared_error\", max_leaf_nodes=number_of_class)\n",
    "    reg = reg.fit(X_train,X_train)\n",
    "    y_pred = reg.predict(X_test) #values in y_pred are cluster centers!\n",
    "    \n",
    "    y_train_pred = reg.predict(X_train)\n",
    "    \n",
    "    unique = np.unique(y_pred, axis=0) # a numpy array with only unique clusters\n",
    "    #train_unique = np.unique(y_train_pred, axis=0)\n",
    "    #print(unique, train_unique)\n",
    "    # assign a cluster index to our prediction points\n",
    "    \n",
    "    cluster_index = np.zeros((y_pred.shape[0], )) \n",
    "    for i, cluster in enumerate(unique):\n",
    "        for j, datapoint in enumerate(y_pred):\n",
    "            if np.array_equal(datapoint, cluster):\n",
    "                cluster_index[j] = int(i)\n",
    "                \n",
    "    train_cluster_index = np.zeros((y_train_pred.shape[0], )) \n",
    "    for i, cluster in enumerate(unique):\n",
    "        for j, datapoint in enumerate(y_train_pred):\n",
    "            if np.array_equal(datapoint, cluster):\n",
    "                train_cluster_index[j] = int(i)\n",
    "    return cluster_index, train_cluster_index\n",
    "    \n",
    "    \n",
    "\n",
    "def get_population_in_cluster_i(number_of_class, y_test, cluster_index, cluster_i):\n",
    "    '''\n",
    "    This is function that returns the number of labels for cluster_i\n",
    "    '''\n",
    "    true_label, counts =  np.unique(y_test[np.where(np.array(cluster_index)==cluster_i)[0]], return_counts=True)\n",
    "    #add dummy into counts \n",
    "    for i in range(number_of_class):\n",
    "        if i not in true_label:\n",
    "            counts = np.insert(counts, i , 0)\n",
    "    return counts\n",
    "\n",
    "def label_assign(y_test, cluster_index, number_of_class):\n",
    "    '''\n",
    "    Perform two accuracy measurements\n",
    "    '''\n",
    "    \n",
    "    # Use the majority rule to assign a label to each cluster\n",
    "    \n",
    "    population_of_cluster = np.asmatrix([get_population_in_cluster_i(number_of_class, y_test, cluster_index, i) for i in range(number_of_class)])\n",
    "    # Assigned label for each cluster\n",
    "    labels = np.argmax(population_of_cluster,axis=1)\n",
    "    labels_simple = []\n",
    "    for i in np.array(labels):\n",
    "        labels_simple.append(i[0])\n",
    "#     print(\"When using the simple majority rule to assign a label to each cluster:\")\n",
    "#     for i, label in enumerate(labels_simple):\n",
    "#         print(\"The label for cluster\", i, \"is:\", label)\n",
    "    \n",
    "    # Majority Rule with assigned weight\n",
    "    \n",
    "    #precentage_in_cluster = normalize(population_of_cluster, axis=1, norm='l1')\n",
    "    #print(precentage_in_cluster)\n",
    "    precentage_in_label = normalize(population_of_cluster, axis=0, norm='l1')\n",
    "    #print(precentage_in_label)\n",
    "    score_matrix = np.multiply(population_of_cluster,precentage_in_label)\n",
    "    #score_matrix\n",
    "    norm_score = normalize(score_matrix, axis=1, norm='l1')\n",
    "    labels_weight = np.argmax(norm_score, axis=1)\n",
    "#     print(\"When using weighted majority rule to assign a label to each cluster:\")\n",
    "#     for i, label in enumerate(labels_weight):\n",
    "#         print(\"The label for cluster\", i, \"is:\", label)\n",
    "    \n",
    "    return labels_simple, labels_weight\n",
    "    \n",
    "def get_accuracy(cluster_new_label, cluster_index, y_test):\n",
    "    labels = [cluster_new_label[int(ci)] for ci in cluster_index]\n",
    "    return accuracy_score(y_test, labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250cf296",
   "metadata": {},
   "source": [
    "What you need to save: cluster_index, labels_simple, labels_weight, accuracy_simple, accuracy_weight FOR BOTH TWO METHODS.\n",
    "\n",
    "If you don't want printed results, comment all print in the function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e6f6236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_regroup(dataset, feature, X_train, X_test, y_train, y_test):\n",
    "    # Wrapper function\n",
    "    number_of_class = len(np.unique(y_test))\n",
    "    cluster_index, train_cluster_index = train(X_train, X_test, y_test, y_train, number_of_class)\n",
    "    labels_simple, labels_weight = label_assign(y_train, train_cluster_index, number_of_class)\n",
    "    print(labels_simple, labels_weight)\n",
    "    \"\"\"\n",
    "    #cluster_index = train(X_train, X_test, y_test, y_train, number_of_class)\n",
    "    labels_simple, labels_weight = label_assign(y_test, cluster_index, number_of_class)\n",
    "\n",
    "    accuracy_simple = get_accuracy(labels_simple, cluster_index, y_test)\n",
    "    accuracy_weight = get_accuracy(labels_weight, cluster_index, y_test)\n",
    "    \"\"\"\n",
    "    accuracy_simple = get_accuracy(labels_simple, cluster_index, y_test)\n",
    "    accuracy_weight = get_accuracy(labels_weight, cluster_index, y_test)\n",
    "    print(\"Accuracy score using unweighted labeling method\", accuracy_simple)\n",
    "    print(\"Accuracy score using weighted labeling method\", accuracy_weight)\n",
    "\n",
    "#     print(\"Accuracy score using unweighted labeling method\", accuracy_simple)\n",
    "#     print(\"Accuracy score using weighted labeling method\", accuracy_weight)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f15021c",
   "metadata": {},
   "source": [
    "## Decision Tree: Merge clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca967a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_merge(X_train, X_test, y_test, y_train, number_of_class):\n",
    "    reg = DecisionTreeRegressor(criterion=\"squared_error\", max_leaf_nodes=50)\n",
    "    reg = reg.fit(X_train,X_train)\n",
    "    y_pred = reg.predict(X_test)\n",
    "    \n",
    "    # Regroup using KMeans\n",
    "    kmeans = KMeans(n_clusters=number_of_class,random_state=0).fit(y_pred)\n",
    "    cluster_index = kmeans.labels_\n",
    "    return cluster_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89e8e2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regroup(dataset, feature, X_train, X_test, y_train, y_test):\n",
    "    # Wrapper function\n",
    "    number_of_class = len(np.unique(y_test))\n",
    "    cluster_index = train_merge(X_train, X_test, y_test, y_train, number_of_class)\n",
    "    labels_simple, labels_weight = label_assign(y_test, cluster_index, number_of_class)\n",
    "\n",
    "    accuracy_simple = get_accuracy(labels_simple, cluster_index, y_test)\n",
    "    accuracy_weight = get_accuracy(labels_weight, cluster_index, y_test)\n",
    "#     print(\"Accuracy score using unweighted labeling method\", accuracy_simple)\n",
    "#     print(\"Accuracy score using weighted labeling method\", accuracy_weight)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6840798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(X_test, y_test, number_of_class):\n",
    "    temp_label = -1\n",
    "    split_at_index = []\n",
    "    for index, label in enumerate(y_test):\n",
    "        if temp_label != label:\n",
    "            #print(\"new label\", label)\n",
    "            temp_label = label\n",
    "            split_at_index.append(index)\n",
    "\n",
    "    label_size = [split_at_index[i+1] - split_at_index[i]for i in range(number_of_class-1)]\n",
    "    label_size.append(len(y_test) - split_at_index[-1] )\n",
    "    minimun = np.min(label_size)\n",
    "    \n",
    "    trim_y = np.concatenate([y_test[split_at_index[i]:(split_at_index[i]+minimun)] for i in range(number_of_class) ], axis=0)\n",
    "    trim_x = np.concatenate([X_test[split_at_index[i]:(split_at_index[i]+minimun)] for i in range(number_of_class) ], axis=0)\n",
    "    \n",
    "\n",
    "    return trim_x, trim_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d6f119e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 0, 3, 1, 2] [4 0 3 1 2]\n",
      "Accuracy score using unweighted labeling method 0.1979381443298969\n",
      "Accuracy score using weighted labeling method 0.1979381443298969\n",
      "0\n",
      "The training took 0.005351 hours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "index = 0\n",
    "\n",
    "for dataset in datasets:\n",
    "    \n",
    "    for feature in features:\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = load_data(feature)\n",
    "        X_test, y_test = trim(X_test, y_test,5)\n",
    "        no_regroup(dataset, feature, X_train, X_test, y_train, y_test)\n",
    "        \n",
    "        print(index)\n",
    "        \n",
    "        index += 1\n",
    "\n",
    "print(\"The training took %f hours\" % ((time.time()-start)/3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa900fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
